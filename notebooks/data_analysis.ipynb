{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7337ad44-cb30-46bd-b949-9ada8203238d",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fd9cd-3de1-4417-a0e2-e29bdc82d7f1",
   "metadata": {},
   "source": [
    "This notebook aims to detect anomalies in financial markets using the Isolation Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ea80c694-2b97-4cb0-8e72-6f3a7b57bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260f04c-6e04-4976-a391-6e829d9e302e",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6639336-fd72-45e2-a0ba-ce4eb11a31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016263695335050746\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('../data/FinancialMarketData.xlsx', sheet_name='EWS' )\n",
    "correlation_matrix = dataset.corr()\n",
    "\n",
    "low_cor_cols=correlation_matrix['Y'][abs(correlation_matrix['Y'])<0.1].index\n",
    "\n",
    "#cleaning data\n",
    "dataset_cleaned=dataset.drop(columns=low_cor_cols)\n",
    "\n",
    "if 'Data' in dataset_cleaned.columns:\n",
    "    dataset_cleaned = dataset_cleaned.drop(columns=['Data'])\n",
    "# Calculer les Q1, Q3 et l'IQR pour chaque colonne\n",
    "Q1 = dataset_cleaned.quantile(0.25)\n",
    "Q3 = dataset_cleaned.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identifier les outliers pour chaque colonne\n",
    "outliers = ((dataset_cleaned < (Q1 - 1.5 * IQR)) | (dataset_cleaned > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "# Compter le nombre d'outliers par colonne\n",
    "outliers_count = outliers.sum()\n",
    "total_outliers=outliers_count.sum()\n",
    "total_entries = dataset_cleaned.shape[0] * dataset_cleaned.shape[1]\n",
    "contamination_estimation = total_outliers / total_entries\n",
    "print(contamination_estimation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb2896-8ee3-4591-b899-26065f48de9c",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aab17815-d141-472d-b4c6-fb0328fd221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "1106    0\n",
      "1107    0\n",
      "1108    0\n",
      "1109    0\n",
      "1110    0\n",
      "Name: Y, Length: 1111, dtype: int64\n",
      "Shape of X_train: (777, 28)\n",
      "Shape of X_test: (334, 28)\n"
     ]
    }
   ],
   "source": [
    "X= dataset_cleaned.drop(columns=['Y'])\n",
    "y=dataset_cleaned['Y']\n",
    "print(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d7d6e-9b30-4ccf-855c-48e94f6e106f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d51da489-7025-4083-994f-fe84ddefd61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.83      0.85       266\n",
      "     Anomaly       0.44      0.51      0.47        68\n",
      "\n",
      "    accuracy                           0.77       334\n",
      "   macro avg       0.65      0.67      0.66       334\n",
      "weighted avg       0.78      0.77      0.77       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Isolation Forest model\n",
    "model = IsolationForest(n_estimators=700, contamination=0.25 , random_state=40)\n",
    "\n",
    "# Training the model on the training set\n",
    "model.fit(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Map predictions (-1 to 1 for anomaly, 1 to 0 for normal)\n",
    "y_pred = np.where(y_pred == -1, 1, 0)\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Normal\", \"Anomaly\"])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
